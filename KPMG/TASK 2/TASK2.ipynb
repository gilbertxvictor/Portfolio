{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPOR RELEVANT LIBRAIES\n",
    "\n",
    "# DATA WRANGLING AND ANALYSIS\n",
    "import pandas as pd\n",
    "import missingno\n",
    "from   skimpy import skim\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from random import choice \n",
    "\n",
    "# DATA VISULIZATION \n",
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DATE MANIPULATION\n",
    "#from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_9908\\2218133990.py:4: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  cusDemo    = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 3 , parse_dates=True)\n"
     ]
    }
   ],
   "source": [
    "# import relevant datasets \n",
    "\n",
    "# CUSTOMER DEMOGRAPHIC DATASET\n",
    "cusDemo    = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 3 , parse_dates=True)\n",
    "\n",
    "#Transation DATA\n",
    "transc     = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 1, parse_dates=True) \n",
    "\n",
    "#CUSTOMER ADDRESS\n",
    "cusAddress = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 4, parse_dates=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING - CUSTOMER DEMOGRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cusDemo_cleaned              = cusDemo.copy() \n",
    "cusDemo_cleaned.drop(columns = ['first_name', 'last_name', 'default'], inplace = True)\n",
    "y  = 2017    \n",
    "cusDemo_cleaned.DOB.fillna(cusDemo_cleaned.DOB.mode()[0], inplace = True)\n",
    "cusDemo_cleaned.DOB = round(y - cusDemo_cleaned.DOB.dt.year).astype(int)\n",
    "cusDemo_cleaned     = cusDemo_cleaned[cusDemo_cleaned.DOB < 100]\n",
    "\n",
    "#GROUP AGE(Countinous) into discrete variables \n",
    "bins    = np.arange(7.5,97.5,5)\n",
    "labels_ = np.arange(10,95,5)\n",
    "cusDemo_cleaned['AgeClass'] = pd.cut(cusDemo_cleaned.DOB, bins, labels = labels_)\n",
    "#cusDemo_cleaned[['AgeClass', 'DOB']]\n",
    "\n",
    "# Function to fill missing values with random integers between 1 and 22\n",
    "def fill_missing_with_random_row(row):\n",
    "    return row.apply(lambda x: np.random.randint(1, 22) if pd.isnull(x) else x)\n",
    "\n",
    "# Apply the function to the specified row\n",
    "cusDemo_cleaned.tenure = fill_missing_with_random_row(cusDemo_cleaned.tenure)\n",
    "\n",
    "\n",
    "\"\"\"Convert thsis statement direclty to a pandas dataframe instead of converting to csv first\"\"\"\n",
    "cusDemo_cleaned[[\"wealth_segment\",\"job_title\",\"job_industry_category\"]].groupby([\"wealth_segment\",\"job_industry_category\"]).value_counts().to_csv(\"check_dist.csv\")\n",
    "dictw = pd.read_csv(\"check_dist.csv\")\n",
    "\n",
    "dictw[(dictw.wealth_segment == \"Affluent Customer\") \n",
    "      & (dictw.job_title == \"Editor\")].job_industry_category.to_list()\n",
    "\n",
    "# Function to fill missing values with random integers between 1 and 22\n",
    "def fill_missing_with_random_row(row):\n",
    "    return row.apply(lambda x: np.random.randint(1, 22) if pd.isnull(x) else x)\n",
    "\n",
    "\n",
    "# Function to fill missing values in column C\n",
    "dictw   = pd.read_csv(\"check_dist.csv\")\n",
    "jic_all = list(dictw.job_industry_category.unique())\n",
    "cusDemo_cleaned \n",
    "\n",
    "def fill_missing_values(cusDemo_cleaned):\n",
    "    for index, row in cusDemo_cleaned.iterrows():\n",
    "        if pd.isnull(row['job_industry_category']):\n",
    "            jic = dictw[(dictw.wealth_segment == row['wealth_segment']) & (dictw.job_title == row['job_title'])].job_industry_category.to_list()\n",
    "            if len(jic) < 1:\n",
    "                 cusDemo_cleaned.at[index, 'job_industry_category'] = choice(jic_all)\n",
    "            else :\n",
    "                cusDemo_cleaned.at[index, 'job_industry_category'] = choice(jic)\n",
    "    return cusDemo_cleaned\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "cusDemo_cleaned = fill_missing_values(cusDemo_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yet to be tested\n",
    "cusDemo_cleaned.job_title.fillna(\"Classified\")\n",
    "\n",
    "#yet to find disparities in gender #U = unspecified gender \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cusDemo_cleaned = cusDemo.copy() \n",
    "\n",
    "##### DROP IRRELEVANT COLUMNS\n",
    "'''\n",
    "Drop  default column, i doesnt have a meaning\n",
    "Drop  default first and last names, Name will not influence purchase pattern\n",
    "'''\n",
    "cusDemo_cleaned.drop(columns = ['first_name', 'last_name', 'default'], inplace = True)\n",
    "#### CLEAN DATE OF BIRTH COLUMN\n",
    "\"\"\" \n",
    "- Convert Date of birth to Age \n",
    "- Drop null values\n",
    "- Find and drop outliers\n",
    "\"\"\"\n",
    "\n",
    "# CONVERT DATE OF BIRTH TO AGE AND CLASSIFY IN TENS \n",
    "#take the maximum transcatodedate as the time of the project \n",
    "y  = 2017    \n",
    "\"\"\"Fill missing age with mode\"\"\"\n",
    "cusDemo_cleaned.DOB.fillna(cusDemo_cleaned.DOB.mode()[0], inplace = True)\n",
    "cusDemo_cleaned.DOB = round(y - cusDemo_cleaned.DOB.dt.year).astype(int)\n",
    "#It seen there is an outlier Age, Lets find out if there are more than one customer that is more than  100 years old \n",
    "\n",
    "\"\"\"\n",
    "Oops!, her just caught an oulier.\n",
    "In a real life situation, we can verify the customer age bu in this case, i will drop the customer from our database \n",
    "and the null date of births\n",
    "\"\"\"\n",
    "cusDemo_cleaned = cusDemo_cleaned[cusDemo_cleaned.DOB < 100]\n",
    "\"\"\"Classify age into bins\"\"\"\n",
    "\n",
    "# Clean job_title','job_industry_category Columns\n",
    "\"\"\"\"\n",
    "- Find cell is missing values\n",
    "- Drop nulls in both category ---> 'job_title','job_industry_category'\n",
    "\"\"\"\n",
    "\n",
    "cusDemo_cleaned.job_industry_category.isna().value_counts()\n",
    "cusDemo_cleaned.dropna(how = 'any')\n",
    "\n",
    "# Attain unique job title to job industry \n",
    "job_to_title = cusDemo_cleaned[['job_title','job_industry_category']].dropna().drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "job_to_title[job_to_title.job_title == 'Blank']\n",
    "              \n",
    "test = cusDemo[['customer_id','DOB']].dropna()\n",
    "test['AGE'] = 2017 - test.DOB.dt.year\n",
    "test.AGE.astype(int)\n",
    "\n",
    "test = test[test != test.AGE.max()]\n",
    "\n",
    "bins = np.arange(10,100,10)\n",
    "labels_ = np.arange(10,90,10)\n",
    "test['Grouping'] = pd.cut(test.AGE, bins, labels = labels_ )\n",
    "test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING - address data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         3999 non-null   int64 \n",
      " 1   address             3999 non-null   object\n",
      " 2   postcode            3999 non-null   int64 \n",
      " 3   state               3999 non-null   object\n",
      " 4   property_valuation  3999 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 156.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cusAddress_cleaned = cusAddress.drop([\"country\"],axis =1) \n",
    "cusAddress_cleaned.state[cusAddress_cleaned.state == \"New South Wales\"] = \"NSW\"\n",
    "cusAddress_cleaned.state[cusAddress_cleaned.state == \"Victoria\"] = \"VIC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA MERGING  - address and demographics data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>DOB</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>default</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>property_valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Laraine</td>\n",
       "      <td>Medendorp</td>\n",
       "      <td>F</td>\n",
       "      <td>93</td>\n",
       "      <td>1953-10-12</td>\n",
       "      <td>Executive Secretary</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>\"'</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>060 Morning Avenue</td>\n",
       "      <td>2016</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Bockman</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>Administrative Officer</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;script&gt;alert('hi')&lt;/script&gt;</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6 Meadow Vale Court</td>\n",
       "      <td>2153</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>1961-10-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>() { _; } &gt;_[$($())] { touch /tmp/blns.shellsh...</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0 Holy Cross Court</td>\n",
       "      <td>4211</td>\n",
       "      <td>QLD</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Sheila-kathryn</td>\n",
       "      <td>Calton</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>1977-05-13</td>\n",
       "      <td>Senior Editor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>NIL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17979 Del Mar Point</td>\n",
       "      <td>2448</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Curr</td>\n",
       "      <td>Duckhouse</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>1966-09-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail</td>\n",
       "      <td>High Net Worth</td>\n",
       "      <td>N</td>\n",
       "      <td>ðµ ð ð ð</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9 Oakridge Court</td>\n",
       "      <td>3216</td>\n",
       "      <td>VIC</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>3996</td>\n",
       "      <td>Rosalia</td>\n",
       "      <td>Halgarth</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>1975-08-09</td>\n",
       "      <td>VP Product Management</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>-100</td>\n",
       "      <td>No</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0 Transport Center</td>\n",
       "      <td>3977</td>\n",
       "      <td>VIC</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>3997</td>\n",
       "      <td>Blanch</td>\n",
       "      <td>Nisuis</td>\n",
       "      <td>Female</td>\n",
       "      <td>87</td>\n",
       "      <td>2001-07-13</td>\n",
       "      <td>Statistician II</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>High Net Worth</td>\n",
       "      <td>N</td>\n",
       "      <td>â¦testâ§</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4 Dovetail Crossing</td>\n",
       "      <td>2350</td>\n",
       "      <td>NSW</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>3998</td>\n",
       "      <td>Sarene</td>\n",
       "      <td>Woolley</td>\n",
       "      <td>U</td>\n",
       "      <td>60</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>IT</td>\n",
       "      <td>High Net Worth</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>736 Roxbury Junction</td>\n",
       "      <td>2540</td>\n",
       "      <td>NSW</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>3999</td>\n",
       "      <td>Patrizius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>11</td>\n",
       "      <td>1973-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Â¡â¢Â£Â¢âÂ§Â¶â¢ÂªÂºââ</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1482 Hauk Trail</td>\n",
       "      <td>3064</td>\n",
       "      <td>VIC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>4000</td>\n",
       "      <td>Kippy</td>\n",
       "      <td>Oldland</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1991-11-05</td>\n",
       "      <td>Software Engineer IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>0/0</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57042 Village Green Point</td>\n",
       "      <td>4511</td>\n",
       "      <td>QLD</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3996 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id      first_name  last_name  gender  \\\n",
       "0               1         Laraine  Medendorp       F   \n",
       "1               2             Eli    Bockman    Male   \n",
       "2               4          Talbot        NaN    Male   \n",
       "3               5  Sheila-kathryn     Calton  Female   \n",
       "4               6            Curr  Duckhouse    Male   \n",
       "...           ...             ...        ...     ...   \n",
       "3991         3996         Rosalia   Halgarth  Female   \n",
       "3992         3997          Blanch     Nisuis  Female   \n",
       "3993         3998          Sarene    Woolley       U   \n",
       "3994         3999       Patrizius        NaN    Male   \n",
       "3995         4000           Kippy    Oldland    Male   \n",
       "\n",
       "      past_3_years_bike_related_purchases        DOB               job_title  \\\n",
       "0                                      93 1953-10-12     Executive Secretary   \n",
       "1                                      81 1980-12-16  Administrative Officer   \n",
       "2                                      33 1961-10-03                     NaN   \n",
       "3                                      56 1977-05-13           Senior Editor   \n",
       "4                                      35 1966-09-16                     NaN   \n",
       "...                                   ...        ...                     ...   \n",
       "3991                                    8 1975-08-09   VP Product Management   \n",
       "3992                                   87 2001-07-13         Statistician II   \n",
       "3993                                   60        NaT       Assistant Manager   \n",
       "3994                                   11 1973-10-24                     NaN   \n",
       "3995                                   76 1991-11-05    Software Engineer IV   \n",
       "\n",
       "     job_industry_category     wealth_segment deceased_indicator  \\\n",
       "0                   Health      Mass Customer                  N   \n",
       "1       Financial Services      Mass Customer                  N   \n",
       "2                       IT      Mass Customer                  N   \n",
       "3                      NaN  Affluent Customer                  N   \n",
       "4                   Retail     High Net Worth                  N   \n",
       "...                    ...                ...                ...   \n",
       "3991                Health      Mass Customer                  N   \n",
       "3992         Manufacturing     High Net Worth                  N   \n",
       "3993                    IT     High Net Worth                  N   \n",
       "3994         Manufacturing  Affluent Customer                  N   \n",
       "3995                   NaN  Affluent Customer                  N   \n",
       "\n",
       "                                                default owns_car  tenure  \\\n",
       "0                                                    \"'      Yes    11.0   \n",
       "1                          <script>alert('hi')</script>      Yes    16.0   \n",
       "2     () { _; } >_[$($())] { touch /tmp/blns.shellsh...       No     7.0   \n",
       "3                                                   NIL      Yes     8.0   \n",
       "4                                              ðµ ð ð ð      Yes    13.0   \n",
       "...                                                 ...      ...     ...   \n",
       "3991                                               -100       No    19.0   \n",
       "3992                                           â¦testâ§      Yes     1.0   \n",
       "3993                                                NaN       No     NaN   \n",
       "3994                             Â¡â¢Â£Â¢âÂ§Â¶â¢ÂªÂºââ       Yes    10.0   \n",
       "3995                                                0/0       No    11.0   \n",
       "\n",
       "                        address  postcode            state  property_valuation  \n",
       "0            060 Morning Avenue      2016  New South Wales                  10  \n",
       "1           6 Meadow Vale Court      2153  New South Wales                  10  \n",
       "2            0 Holy Cross Court      4211              QLD                   9  \n",
       "3           17979 Del Mar Point      2448  New South Wales                   4  \n",
       "4              9 Oakridge Court      3216              VIC                   9  \n",
       "...                         ...       ...              ...                 ...  \n",
       "3991         0 Transport Center      3977              VIC                   6  \n",
       "3992        4 Dovetail Crossing      2350              NSW                   2  \n",
       "3993       736 Roxbury Junction      2540              NSW                   6  \n",
       "3994            1482 Hauk Trail      3064              VIC                   3  \n",
       "3995  57042 Village Green Point      4511              QLD                   6  \n",
       "\n",
       "[3996 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_data = cusDemo_cleaned.merge(cusAddress_cleaned, how = \"inner\", on = \"customer_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING - transcation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the transaaction data \n",
    "trans_cleaned = transc.copy()\n",
    "\n",
    "#Did customerss buy similar items??  - different items were purchased at diffrent timers \n",
    "len(trans_cleaned.product_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    20001\n",
       "True         1\n",
       "Name: transaction_id, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate if there multiple transactions recorded \n",
    "trans_cleaned.transaction_id.duplicated().value_counts()\n",
    "\n",
    "\n",
    "# Convert product_first_sold_date to the right format \n",
    "trans_cleaned['product_first_sold_date'] = pd.to_datetime(trans_cleaned['product_first_sold_date'], \n",
    "                                           unit = 'D',\n",
    "                                           origin ='1899-12-30' )\n",
    "\n",
    "\n",
    "#Convert online type to Boolean\n",
    "def changeBoolean(var):\n",
    "    if var == 0.0:\n",
    "        return False\n",
    "    elif var == 1.0:\n",
    "        return True\n",
    "    \n",
    "trans_cleaned['online_order'] = trans_cleaned['online_order'].apply(changeBoolean)\n",
    "\n",
    "# ADD a profit column and profit ratio\n",
    "trans_cleaned['profit']      = trans_cleaned['list_price'] - trans_cleaned['standard_cost']\n",
    "trans_cleaned['profitRatio'] = trans_cleaned['list_price'] / trans_cleaned['standard_cost']\n",
    "\n",
    "# drop columns with null profit \n",
    "trans_cleaned          = trans_cleaned[trans_cleaned['profit'].notna()]\n",
    "trans_cleaned.info()\n",
    "\n",
    "\n",
    "## ADD AN UNSPECIFIED COLUMN TO online_order that is na\n",
    "trans_cleaned.online_order.fillna('Unspecified', inplace=True)\n",
    "\n",
    "# Find all categorical columns \n",
    "columns = [i for i in list(trans_cleaned.columns) if trans_cleaned[i].dtype == 'O']\n",
    "\n",
    "for item in columns:\n",
    "    print(f'{item} unique Values {trans_cleaned[item].unique()}')\n",
    "    \n",
    "\n",
    "# Observe thatcertain transactions were cancelled and note that Cancelled transactions dont add up to the revenue\n",
    "trans_cleaned.order_status.value_counts() \n",
    "\n",
    "# Use only approved transcations \n",
    "trans_cleaned = trans_cleaned[trans_cleaned.order_status == 'Approved']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE  RELEVANT METRICS I USE WILL BE \n",
    "- TOTAL AND AVERAGE REVENUE PER CUSTOMER \n",
    "- FREQUENCY OF TRANSCATION \n",
    "- AVERAGE PROFIT RATION  PER TRANSACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcMetrics = trans_cleaned.groupby('customer_id').agg({'profit' : ['sum', 'mean'],\n",
    "                                          \"customer_id\" : 'count' ,\n",
    "                                          'profitRatio' : ['sum', 'mean']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING\n",
    "ALL DATA SETS ARE CLEANED INORDER TO BE PREPROCESSED.\n",
    "REDUNDANT COLUMNS ARE DROPPED, MISSING VALUES ARE FILLED, CATEGORIES ARE CORRECTED. \n",
    "\n",
    "#### DATA WRANGLING\n",
    "DATA IS WRANGLED TO FIT INTO ONE ONE DATASET \n",
    "\n",
    "#### COMPUTATION\n",
    "- COMPUTE AGE AND CLASSIFY BY AGE BRACKET\n",
    "\n",
    "- AN APPROPRIATE METHOD IS USED TO CLASSIFY CURRENT TARGET- 1,0 WHICH WILL CORRESEPOND TO TRUE OR FALSE\n",
    "  PROBLEM?? -- EHAT METHOD CAN I USE TO DESIGN A MODEL THAT CAN EFFECTIVELY CATEGORISE TH\n",
    "\n",
    "#### VISUALIZATION AND CLASSIFICATION OF PUCAHSE BEHAVIOURS \n",
    "EDA IS CARRIED OUT O THE EXISTING DATASET AND MORE UNDERSTANDING OF THE PURCHASE BEHAVIOURS IS ATTAINED \n",
    "\n",
    "#### FEATURE ENGINEERING \n",
    "THE DATA SET IS ACCUSTOMED TO BE FIT INTO A MODEL\n",
    "\n",
    "#### DEVELOP MODEL \n",
    "IN THIS CASE, WE WILL USE A CLASSICAL CLASSIFICTION MODEL TO CLASSIFY CUSKTOMERS INTO TWO GROUPS BASED ON THEIR PURCHASE BEHAVIOUS \n",
    "\n",
    "#### MODEL TESTING AND VALIDATION \n",
    "THE MODEL IS TESTED WITH THE TEST DATA TO VALIDATE THE CORRECTIES NESSA ND ACCUERACY\n",
    "\n",
    "#### MODEL DEPLOYMENT\n",
    "APPLY MODEL ON THE NEW CUSTOMERS FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "585a938ec471c889bf0cce0aed741a99eaf47ca09c0fa8393793bc5bfe77ba11"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
