{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT RELEVANT LIBRAIES\n",
    "\n",
    "# DATA WRANGLING AND ANALYSIS\n",
    "import pandas   as pd\n",
    "import datetime as dt\n",
    "import numpy    as np\n",
    "from   skimpy   import skim\n",
    "from   random   import choice \n",
    "#import missingno\n",
    "\n",
    "# DATA VISULIZATION \n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DATE MANIPULATION\n",
    "#from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_5112\\503302315.py:4: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  cusDemo    = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 3 , parse_dates=True)\n"
     ]
    }
   ],
   "source": [
    "# import relevant datasets \n",
    "\n",
    "# CUSTOMER DEMOGRAPHIC DATASET\n",
    "cusDemo    = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 3 , parse_dates=True)\n",
    "#Transation DATA\n",
    "transc     = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 1, parse_dates=True) \n",
    "#CUSTOMER ADDRESS\n",
    "cusAddress = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx', sheet_name = 4, parse_dates=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING - CUSTOMER DEMOGRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cusDemo_cleaned              = cusDemo.copy() \n",
    "cusDemo_cleaned.drop(columns = ['first_name', 'last_name', 'default'], inplace = True)\n",
    "\n",
    "#Clean up gender column\n",
    "cusDemo_cleaned.gender = df['Gender'].replace({ 'Male': 'M',\n",
    "                                                'Female': 'F',\n",
    "                                                'Femal': 'F'})\n",
    "\n",
    "y  = 2017    \n",
    "cusDemo_cleaned.DOB.fillna(cusDemo_cleaned.DOB.mode()[0], inplace = True)\n",
    "cusDemo_cleaned.DOB = round(y - cusDemo_cleaned.DOB.dt.year).astype(int)\n",
    "cusDemo_cleaned     = cusDemo_cleaned[cusDemo_cleaned.DOB < 100]\n",
    "\n",
    "#GROUP AGE(Countinous) into discrete variables \n",
    "bins    = np.arange(7.5,97.5,5)\n",
    "labels_ = np.arange(10,95,5)\n",
    "cusDemo_cleaned['AgeClass'] = pd.cut(cusDemo_cleaned.DOB, bins, labels = labels_)\n",
    "#cusDemo_cleaned[['AgeClass', 'DOB']]\n",
    "\n",
    "# Function to fill missing values with random integers between 1 and 22\n",
    "def fill_missing_with_random_row(row):\n",
    "    return row.apply(lambda x: np.random.randint(1, 22) if pd.isnull(x) else x)\n",
    "\n",
    "# Apply the function to the specified row\n",
    "cusDemo_cleaned.tenure = fill_missing_with_random_row(cusDemo_cleaned.tenure)\n",
    "\n",
    "\n",
    "\"\"\"Convert thsis statement direclty to a pandas dataframe instead of converting to csv first\"\"\"\n",
    "#cusDemo_cleaned[[\"wealth_segment\",\"job_title\",\"job_industry_category\"]].groupby([\"wealth_segment\",\"job_industry_category\"]).value_counts().to_csv(\"check_dist.csv\")\n",
    "dictw = pd.read_csv(\"check_dist.csv\")\n",
    "\n",
    "dictw[(dictw.wealth_segment == \"Affluent Customer\") \n",
    "      & (dictw.job_title == \"Editor\")].job_industry_category.to_list()\n",
    "\n",
    "# Function to fill missing values in column C\n",
    "jic_all = list(dictw.job_industry_category.unique())\n",
    "cusDemo_cleaned \n",
    "\n",
    "def fill_missing_values(cusDemo_cleaned):\n",
    "    for index, row in cusDemo_cleaned.iterrows():\n",
    "        if pd.isnull(row['job_industry_category']):\n",
    "            jic = dictw[(dictw.wealth_segment == row['wealth_segment']) & (dictw.job_title == row['job_title'])].job_industry_category.to_list()\n",
    "            if len(jic) < 1:\n",
    "                 cusDemo_cleaned.at[index, 'job_industry_category'] = choice(jic_all)\n",
    "            else :\n",
    "                cusDemo_cleaned.at[index, 'job_industry_category'] = choice(jic)\n",
    "    return cusDemo_cleaned\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "cusDemo_cleaned = fill_missing_values(cusDemo_cleaned)\n",
    "\n",
    "#Yet to be tested\n",
    "cusDemo_cleaned.job_title.fillna(\"Unspecified\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3999 entries, 0 to 3999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                               Non-Null Count  Dtype   \n",
      "---  ------                               --------------  -----   \n",
      " 0   customer_id                          3999 non-null   int64   \n",
      " 1   gender                               3999 non-null   object  \n",
      " 2   past_3_years_bike_related_purchases  3999 non-null   int64   \n",
      " 3   DOB                                  3999 non-null   int32   \n",
      " 4   job_title                            3999 non-null   object  \n",
      " 5   job_industry_category                3999 non-null   object  \n",
      " 6   wealth_segment                       3999 non-null   object  \n",
      " 7   deceased_indicator                   3999 non-null   object  \n",
      " 8   owns_car                             3999 non-null   object  \n",
      " 9   tenure                               3999 non-null   float64 \n",
      " 10  AgeClass                             3999 non-null   category\n",
      "dtypes: category(1), float64(1), int32(1), int64(2), object(6)\n",
      "memory usage: 461.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cusDemo_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cusDemo_cleaned = cusDemo.copy() \n",
    "\n",
    "##### DROP IRRELEVANT COLUMNS\n",
    "'''\n",
    "Drop  default column, i doesnt have a meaning\n",
    "Drop  default first and last names, Name will not influence purchase pattern\n",
    "'''\n",
    "cusDemo_cleaned.drop(columns = ['first_name', 'last_name', 'default'], inplace = True)\n",
    "#### CLEAN DATE OF BIRTH COLUMN\n",
    "\"\"\" \n",
    "- Convert Date of birth to Age \n",
    "- Drop null values\n",
    "- Find and drop outliers\n",
    "\"\"\"\n",
    "\n",
    "# CONVERT DATE OF BIRTH TO AGE AND CLASSIFY IN TENS \n",
    "#take the maximum transcatodedate as the time of the project \n",
    "y  = 2017    \n",
    "\"\"\"Fill missing age with mode\"\"\"\n",
    "cusDemo_cleaned.DOB.fillna(cusDemo_cleaned.DOB.mode()[0], inplace = True)\n",
    "cusDemo_cleaned.DOB = round(y - cusDemo_cleaned.DOB.dt.year).astype(int)\n",
    "#It seen there is an outlier Age, Lets find out if there are more than one customer that is more than  100 years old \n",
    "\n",
    "\"\"\"\n",
    "Oops!, her just caught an oulier.\n",
    "In a real life situation, we can verify the customer age bu in this case, i will drop the customer from our database \n",
    "and the null date of births\n",
    "\"\"\"\n",
    "cusDemo_cleaned = cusDemo_cleaned[cusDemo_cleaned.DOB < 100]\n",
    "\"\"\"Classify age into bins\"\"\"\n",
    "\n",
    "# Clean job_title','job_industry_category Columns\n",
    "\"\"\"\"\n",
    "- Find cell is missing values\n",
    "- Drop nulls in both category ---> 'job_title','job_industry_category'\n",
    "\"\"\"\n",
    "\n",
    "cusDemo_cleaned.job_industry_category.isna().value_counts()\n",
    "cusDemo_cleaned.dropna(how = 'any')\n",
    "\n",
    "# Attain unique job title to job industry \n",
    "job_to_title = cusDemo_cleaned[['job_title','job_industry_category']].dropna().drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "job_to_title[job_to_title.job_title == 'Blank']\n",
    "              \n",
    "test = cusDemo[['customer_id','DOB']].dropna()\n",
    "test['AGE'] = 2017 - test.DOB.dt.year\n",
    "test.AGE.astype(int)\n",
    "\n",
    "test = test[test != test.AGE.max()]\n",
    "\n",
    "bins = np.arange(10,100,10)\n",
    "labels_ = np.arange(10,90,10)\n",
    "test['Grouping'] = pd.cut(test.AGE, bins, labels = labels_ )\n",
    "test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING - address data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_2812\\191615168.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cusAddress_cleaned.state[cusAddress_cleaned.state == \"New South Wales\"] = \"NSW\"\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_2812\\191615168.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cusAddress_cleaned.state[cusAddress_cleaned.state == \"Victoria\"] = \"VIC\"\n"
     ]
    }
   ],
   "source": [
    "cusAddress_cleaned = cusAddress.drop([\"country\"],axis =1) \n",
    "cusAddress_cleaned.state[cusAddress_cleaned.state == \"New South Wales\"] = \"NSW\"\n",
    "cusAddress_cleaned.state[cusAddress_cleaned.state == \"Victoria\"] = \"VIC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA MERGING  - address and demographics data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = cusDemo_cleaned.merge(cusAddress_cleaned, how = \"inner\", on = \"customer_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING - transcation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the transaaction data \n",
    "trans_cleaned = transc.copy()\n",
    "\n",
    "# Investigate if there multiple transactions recorded \n",
    "trans_cleaned.transaction_id.duplicated().value_counts()\n",
    "\"\"\"No duplicate transaction Id\"\"\"\n",
    "\n",
    "# Convert product_first_sold_date to the right format \n",
    "trans_cleaned['product_first_sold_date'] = pd.to_datetime(trans_cleaned['product_first_sold_date'],\n",
    "                                           unit = 'D',\n",
    "                                           origin ='1899-12-30' )\n",
    "\n",
    "#Convert online type to Boolean\n",
    "def changeBoolean(var):\n",
    "    if   var == 0.0:\n",
    "        return False\n",
    "    elif var == 1.0:\n",
    "        return True\n",
    "    else           :\n",
    "        return True \n",
    "    \n",
    "trans_cleaned['online_order'] = trans_cleaned['online_order'].apply(changeBoolean)\n",
    "trans_cleaned.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD a profit column and profit ratio\n",
    "trans_cleaned['profit']      = trans_cleaned['list_price'] - trans_cleaned['standard_cost']\n",
    "trans_cleaned['profitRatio'] = trans_cleaned['list_price'] / trans_cleaned['standard_cost']\n",
    "\n",
    "# drop columns with null profit \n",
    "trans_cleaned          = trans_cleaned[trans_cleaned['profit'].notna()]\n",
    "\n",
    "## ADD AN UNSPECIFIED COLUMN TO online_order that is na\n",
    "trans_cleaned.online_order.fillna('Unspecified', inplace=True)\n",
    "\n",
    "# Find all categorical columns \n",
    "columns = [i for i in list(trans_cleaned.columns) if trans_cleaned[i].dtype == 'O']\n",
    "\n",
    "for item in columns:\n",
    "    print(f'{item} unique Values {trans_cleaned[item].unique()}')\n",
    "    \n",
    "# Observe thatcertain transactions were cancelled and note that Cancelled transactions dont add up to the revenue\n",
    "trans_cleaned.order_status.value_counts() \n",
    "\n",
    "# Use only approved transcations \n",
    "trans_cleaned = trans_cleaned[trans_cleaned.order_status == 'Approved']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE  RELEVANT METRICS I USE WILL BE \n",
    "- TOTAL AND AVERAGE REVENUE PER CUSTOMER \n",
    "- FREQUENCY OF TRANSCATION \n",
    "- AVERAGE PROFIT RATION  PER TRANSACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcMetrics = trans_cleaned.groupby('customer_id').agg({'profit' : ['sum', 'mean'],\n",
    "                                          \"customer_id\" : 'count' ,\n",
    "                                          'profitRatio' : ['sum', 'mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING\n",
    "ALL DATA SETS ARE CLEANED INORDER TO BE PREPROCESSED.\n",
    "REDUNDANT COLUMNS ARE DROPPED, MISSING VALUES ARE FILLED, CATEGORIES ARE CORRECTED. \n",
    "\n",
    "#### DATA WRANGLING\n",
    "DATA IS WRANGLED TO FIT INTO ONE ONE DATASET \n",
    "\n",
    "#### COMPUTATION\n",
    "- COMPUTE AGE AND CLASSIFY BY AGE BRACKET\n",
    "\n",
    "- AN APPROPRIATE METHOD IS USED TO CLASSIFY CURRENT TARGET- 1,0 WHICH WILL CORRESEPOND TO TRUE OR FALSE\n",
    "  PROBLEM?? -- EHAT METHOD CAN I USE TO DESIGN A MODEL THAT CAN EFFECTIVELY CATEGORISE TH\n",
    "\n",
    "#### VISUALIZATION AND CLASSIFICATION OF PUCAHSE BEHAVIOURS \n",
    "EDA IS CARRIED OUT O THE EXISTING DATASET AND MORE UNDERSTANDING OF THE PURCHASE BEHAVIOURS IS ATTAINED \n",
    "\n",
    "#### FEATURE ENGINEERING \n",
    "THE DATA SET IS ACCUSTOMED TO BE FIT INTO A MODEL\n",
    "\n",
    "#### DEVELOP MODEL \n",
    "IN THIS CASE, WE WILL USE A CLASSICAL CLASSIFICTION MODEL TO CLASSIFY CUSKTOMERS INTO TWO GROUPS BASED ON THEIR PURCHASE BEHAVIOUS \n",
    "\n",
    "#### MODEL TESTING AND VALIDATION \n",
    "THE MODEL IS TESTED WITH THE TEST DATA TO VALIDATE THE CORRECTIES NESSA ND ACCUERACY\n",
    "\n",
    "#### MODEL DEPLOYMENT\n",
    "APPLY MODEL ON THE NEW CUSTOMERS FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "585a938ec471c889bf0cce0aed741a99eaf47ca09c0fa8393793bc5bfe77ba11"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
